CREATE OR REPLACE TABLE EMP (
    EMPID INTEGER PRIMARY KEY,
    EMPNAME VARCHAR(100),
    LOCATION VARCHAR(100)
);
SELECT * FROM EMP;


-- COPYTING DATA FROM S3 BUCKET TO TABLE. ----------------------


COPY INTO EMP
FROM s3://nvt/snowflake/Raw_data/Emp/emp
CREDENTIALS=(AWS_KEY_ID = 'AKIAQKK7J6DGFVEEDCA2' AWS_SECRET_KEY = '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')
FILE_FORMAT = (TYPE=CSV)


SELECT * FROM EMP;

-- STORAGE INTEGRATION : ESTABLISHES CONNECTION BW SNOWFLAKE AND ANY CLOUD. AWS
CREATE OR REPLACE STORAGE INTEGRATION AWS_S3_SOURCE_DATA
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::022211588300:role/s3_Snowflake_load'  -- ARN: amazon resource number, unique number provided to all the resources/object in Aws.
ENABLED = TRUE
STORAGE_ALLOWED_LOCATIONS = ('s3://nvt');  -- integration is allowed till nvt only.

-- describe integration AWS_S3_SOURCE_DATA  -- PARAMETERS OF THE STORAGE INTEGRATION

-- NOW COPYING DATA INTO SNOWFLAKE BY USING STORAGE INTEGRATION (UNLIKE PREV. USING ACCESS KEY AND SECRET KEY)

COPY INTO EMP
FROM s3://nvt/snowflake/Raw_data/Emp/emp
STORAGE_INTEGRATION = AWS_S3_SOURCE_DATA
FILE_FORMAT = (TYPE=CSV)
FORCE = TRUE  -- IF DATA IS ALREADY COPIED IT WILL NOT COPY AGAIN SO FOR FORCEFULLY COPYING DATA THIS IS TRUE.

SELECT * FROM EMP;

-- CONTAIN ALL THE METADATA OF THE COPY HISTORY

SELECT * FROM TABLE (INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME => 'EMP', START_TIME=>DATEADD(HOURS, -1, CURRENT_TIMESTAMP())))

==========================================================================================================================================


-- -- // Data Unloading


COPY INTO 's3://nvt/snowflake/Raw_data/emp/'
FROM EMP
STORAGE_INTEGRATION=AWS_S3_SOURCE_DATA
FILE_FORMAT=(TYPE=CSV)
OVERWRITE=TRUE;  -- if already a file is present it will overwrites it

-- using STORAGE INTEGRATION


COPY INTO @STG_S3_SOURCE_DATA/
FROM DEPT
FILE_FORMAT=(TYPE_FORMAT=CSV COMPRESSION = NONE);